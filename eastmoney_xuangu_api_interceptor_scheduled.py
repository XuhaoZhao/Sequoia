"""
ä¸œæ–¹è´¢å¯Œé€‰è‚¡ search-code API æ‹¦æˆªå™¨

ä½¿ç”¨ Selenium æ‹¦æˆªä¸œæ–¹è´¢å¯Œé€‰è‚¡é¡µé¢çš„ search-code API
ç›®æ ‡API: https://np-tjxg-g.eastmoney.com/api/smart-tag/stock/v3/pw/search-code

ç‰¹ç‚¹ï¼š
1. åªæ‹¦æˆª search-code API
2. è¿‡æ»¤æ‰æµå¼å“åº”ä¸­æ— æ•°æ®çš„å“åº”
3. æ¯5åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°é¡µé¢
4. ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿè®°å½•æ‰€æœ‰æ“ä½œ
"""

import time
import json
from datetime import datetime
import requests
import random
import string
import csv
import os
from db_manager import IndustryDataDB
# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
try:
    from financial_framework.logger_config import FinancialLogger, get_logger
    from financial_framework.selenium_browser_manager import SeleniumBrowserManager
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼ˆç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼‰ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    from logger_config import FinancialLogger, get_logger
    from selenium_browser_manager import SeleniumBrowserManager

class EastmoneySearchCodeInterceptor:
    """
    ä½¿ç”¨ Selenium æ‹¦æˆªä¸œæ–¹è´¢å¯Œé€‰è‚¡é¡µé¢çš„ search-code API
    """
    def __init__(self, headless=False, log_full_data=False, log_summary_only=False, use_database=True):
        """
        åˆå§‹åŒ–æ‹¦æˆªå™¨
        :param headless: æ˜¯å¦æ— å¤´æ¨¡å¼(ä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£)
        :param log_full_data: æ˜¯å¦è®°å½•å®Œæ•´çš„è¯·æ±‚å’Œå“åº”æ•°æ®åˆ°æ•°æ®æ—¥å¿—ï¼ˆé»˜è®¤Falseï¼‰
        :param log_summary_only: æ˜¯å¦åªè®°å½•å…³é”®æ‘˜è¦ä¿¡æ¯åˆ°æ§åˆ¶å°ï¼ˆé»˜è®¤Falseï¼ŒTrueæ—¶ä»…æ˜¾ç¤ºå…³é”®ç»Ÿè®¡ä¿¡æ¯ï¼‰
        :param use_database: æ˜¯å¦ä½¿ç”¨æ•°æ®åº“ä¿å­˜æ•°æ®ï¼ˆé»˜è®¤Trueï¼‰
        """
        # åˆå§‹åŒ–æ—¥å¿—å™¨
        self.logger = get_logger('financial_framework.eastmoney_interceptor')
        self.data_logger = FinancialLogger.get_data_logger()

        # ä½¿ç”¨ SeleniumBrowserManager ç®¡ç†æµè§ˆå™¨
        self.browser_manager = SeleniumBrowserManager(
            headless=headless,
            logger_name='financial_framework.eastmoney_interceptor.browser'
        )

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self.use_database = use_database
        try:
            # å»¶è¿Ÿå¯¼å…¥æ•°æ®åº“ç®¡ç†å™¨
            self.db = IndustryDataDB("industry_data.db")
            self.logger.info("âœ“ æ•°æ®åº“è¿æ¥å·²å»ºç«‹ï¼Œå°†ä½¿ç”¨æ•°æ®åº“ä¿å­˜æ•°æ®")
        except Exception as e:
            self.logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨CSVä¿å­˜æ–¹å¼")
            self.use_database = False
            self.db = None

              # API URLæ˜ å°„è¡¨
        self.api_url_map = {
            "stock": "https://np-tjxg-g.eastmoney.com/api/smart-tag/stock/v3/pw/search-code",
            "etf": "https://np-tjxg-g.eastmoney.com/api/smart-tag/etf/v3/pw/search-code",
            "fund": "https://np-tjxg-g.eastmoney.com/api/smart-tag/fund/v3/pw/search-code",
            "bond": "https://np-tjxg-g.eastmoney.com/api/smart-tag/bond/v3/pw/search-code"
        }
        self.target_api_url = self.api_url_map.get("stock", self.api_url_map["stock"])  # é»˜è®¤ä½¿ç”¨stockç±»å‹
        self.requested_pages = set()  # ç”¨äºè·Ÿè¸ªå·²è¯·æ±‚è¿‡çš„é¡µç ,é¿å…é‡å¤è¯·æ±‚

        # æ—¥å¿—æ§åˆ¶å‚æ•°
        self.log_full_data = log_full_data
        self.log_summary_only = log_summary_only

        self.logger.info("åˆå§‹åŒ–ä¸œæ–¹è´¢å¯Œé€‰è‚¡APIæ‹¦æˆªå™¨")
        self.logger.info(f"æ—¥å¿—é…ç½®: å®Œæ•´æ•°æ®={log_full_data}, ä»…æ‘˜è¦={log_summary_only}")
        self.browser_manager.init_driver()


    def _randomize_request_id(self, original_id):
        """
        éšæœºæ›¿æ¢requestIdä¸­çš„å‡ ä¸ªå­—ç¬¦,é¿å…åçˆ¬
        :param original_id: åŸå§‹çš„requestId
        :return: ä¿®æ”¹åçš„requestId
        """
        if not original_id or not isinstance(original_id, str):
            return original_id

        # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿ä¿®æ”¹
        id_chars = list(original_id)
        id_length = len(id_chars)

        if id_length == 0:
            return original_id

        # éšæœºæ›¿æ¢3-5ä¸ªå­—ç¬¦(æ ¹æ®é•¿åº¦è°ƒæ•´)
        num_chars_to_replace = min(random.randint(3, 5), id_length // 3)

        # éšæœºé€‰æ‹©è¦æ›¿æ¢çš„ä½ç½®
        positions_to_replace = random.sample(range(id_length), num_chars_to_replace)

        for pos in positions_to_replace:
            original_char = id_chars[pos]

            # æ ¹æ®åŸå­—ç¬¦ç±»å‹é€‰æ‹©æ›¿æ¢å­—ç¬¦
            if original_char.isdigit():
                # æ•°å­—æ›¿æ¢ä¸ºæ•°å­—
                id_chars[pos] = random.choice(string.digits)
            elif original_char.islower():
                # å°å†™å­—æ¯æ›¿æ¢ä¸ºå°å†™å­—æ¯
                id_chars[pos] = random.choice(string.ascii_lowercase)
            elif original_char.isupper():
                # å¤§å†™å­—æ¯æ›¿æ¢ä¸ºå¤§å†™å­—æ¯
                id_chars[pos] = random.choice(string.ascii_uppercase)
            else:
                # å…¶ä»–å­—ç¬¦ä¿æŒä¸å˜
                pass

        new_id = ''.join(id_chars)
        self.logger.debug(f"requestIdéšæœºåŒ–: {original_id[:20]}... â†’ {new_id[:20]}...")
        return new_id

    def _request_next_page(self, request_info, request_json, first_page_response=None, type="stock"):
        """
        æ ¹æ®ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼Œè‡ªåŠ¨è¯·æ±‚æ‰€æœ‰åˆ†é¡µå¹¶æ”¶é›†å…³é”®æ•°æ®
        :param request_info: åŸå§‹è¯·æ±‚ä¿¡æ¯
        :param request_json: åŸå§‹è¯·æ±‚çš„JSONæ•°æ®
        :param first_page_response: ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
        :param type: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤ï¼š"stock"ï¼‰
        """
        try:
            # é¿å…é‡å¤è¯·æ±‚
            if hasattr(self, '_is_requesting_all_pages') and self._is_requesting_all_pages:
                return

            self._is_requesting_all_pages = True

            # è§£æç¬¬ä¸€é¡µæ•°æ®ï¼Œè·å–totalå’ŒdataList
            if not first_page_response:
                self.logger.warning("æœªæä¾›ç¬¬ä¸€é¡µå“åº”æ•°æ®ï¼Œæ— æ³•è¯·æ±‚åç»­åˆ†é¡µ")
                return

            # æå–totalå’ŒdataList
            try:
                data = first_page_response.get('data', {})
                result = data.get('result', {})
                total = result.get('total', 0)
                first_page_data_list = result.get('dataList', [])

                if not self.log_summary_only:
                    self.logger.info("=" * 80)
                    self.logger.info(f"ç¬¬ä¸€é¡µæ•°æ®è§£æ:")
                    self.logger.info(f"  æ€»è®°å½•æ•°(total): {total}")
                    self.logger.info(f"  ç¬¬ä¸€é¡µæ•°æ®æ¡æ•°: {len(first_page_data_list)}")
                    self.logger.info("=" * 80)
                else:
                    self.logger.info(f"ğŸ“Š ç¬¬ä¸€é¡µ: æ€»æ•°{total} | è¿”å›{len(first_page_data_list)}æ¡")

                if total == 0:
                    self.logger.warning("æ€»è®°å½•æ•°ä¸º0ï¼Œæ— éœ€è¯·æ±‚åç»­åˆ†é¡µ")
                    return

                # æ”¶é›†æ‰€æœ‰æ•°æ®
                all_data_list = first_page_data_list.copy()

            except Exception as e:
                self.logger.error(f"è§£æç¬¬ä¸€é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                return

            # è®¡ç®—æ€»é¡µæ•°
            page_size = request_json.get('pageSize', 50)
            total_pages = (total + page_size - 1) // page_size  # å‘ä¸Šå–æ•´

            if not self.log_summary_only:
                self.logger.info(f"æ¯é¡µå¤§å°: {page_size}")
                self.logger.info(f"è®¡ç®—æ€»é¡µæ•°: {total_pages}")
                self.logger.info("=" * 80)
            else:
                self.logger.info(f"ğŸ“„ åˆ†é¡µ: {total_pages}é¡µ Ã— {page_size}æ¡/é¡µ")

            # å¦‚æœåªæœ‰ä¸€é¡µï¼Œç›´æ¥è¿”å›
            if total_pages <= 1:
                self.logger.info("åªæœ‰1é¡µæ•°æ®ï¼Œæ— éœ€è¯·æ±‚åç»­åˆ†é¡µ")
                self._log_all_key_data(total, all_data_list)
                return

            # è¯·æ±‚åç»­é¡µé¢ (ä»ç¬¬2é¡µå¼€å§‹)
            url = request_info['request_url']
            headers = request_info['request_headers'].copy()
            headers['Content-Type'] = 'application/json'

            for page_no in range(2, total_pages + 1):
                # æ£€æŸ¥æ˜¯å¦å·²è¯·æ±‚è¿‡
                if page_no in self.requested_pages:
                    continue

                self.requested_pages.add(page_no)

                # å»¶æ—¶1ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                if not self.log_summary_only:
                    self.logger.info(f"å»¶æ—¶1ç§’åè¯·æ±‚ç¬¬{page_no}é¡µ...")
                time.sleep(1)

                # å¤åˆ¶è¯·æ±‚æ•°æ®
                next_page_json = request_json.copy()

                # ä¿®æ”¹é¡µç 
                if 'pageNo' in next_page_json:
                    next_page_json['pageNo'] = page_no
                elif 'pageNum' in next_page_json:
                    next_page_json['pageNum'] = page_no
                elif 'page' in next_page_json:
                    next_page_json['page'] = page_no

                # éšæœºåŒ–requestIdï¼Œé¿å…åçˆ¬
                if 'requestId' in next_page_json:
                    next_page_json['requestId'] = self._randomize_request_id(next_page_json['requestId'])

                # å‘èµ·è¯·æ±‚
                if not self.log_summary_only:
                    self.logger.info(f"æ­£åœ¨è¯·æ±‚ç¬¬{page_no}/{total_pages}é¡µ...")
                    self.logger.info(f"è¯·æ±‚URL: {url}")
                else:
                    self.logger.info(f"ğŸ”„ è¯·æ±‚ç¬¬{page_no}/{total_pages}é¡µ...")

                try:
                    response = requests.post(
                        url,
                        json=next_page_json,
                        headers=headers,
                        timeout=30
                    )

                    if response.status_code == 200:
                        if not self.log_summary_only:
                            self.logger.info(f"âœ“ ç¬¬{page_no}é¡µè¯·æ±‚æˆåŠŸ! çŠ¶æ€ç : {response.status_code}")
                            self.logger.info(f"âœ“ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")
                        else:
                            self.logger.info(f"  âœ“ ç¬¬{page_no}é¡µæˆåŠŸ ({len(response.text)}å­—ç¬¦)")

                        # è§£æå“åº”æ•°æ®
                        try:
                            page_response_json = response.json()
                            page_data = page_response_json.get('data', {})
                            page_result = page_data.get('result', {})
                            page_data_list = page_result.get('dataList', [])

                            if not self.log_summary_only:
                                self.logger.info(f"âœ“ ç¬¬{page_no}é¡µæ•°æ®æ¡æ•°: {len(page_data_list)}")
                            else:
                                self.logger.info(f"    è¿”å› {len(page_data_list)} æ¡æ•°æ®")

                            # æ”¶é›†æ•°æ®
                            all_data_list.extend(page_data_list)

                            # æ„é€ å“åº”æ•°æ®ä¿¡æ¯å¹¶è®°å½•åˆ°æ•°æ®æ—¥å¿—
                            api_info = {
                                'url': url,
                                'status': response.status_code,
                                'request_id': f'manual_page_{page_no}',
                                'method': 'POST',
                                'intercept_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                'intercept_timestamp': datetime.now().isoformat(),
                                'intercept_index': f'page_{page_no}_manual',
                                'request_url': url,
                                'request_method': 'POST',
                                'request_params': {
                                    'pageNo': page_no,
                                    'pageSize': page_size,
                                    'keyWord': next_page_json.get('keyWord', '')
                                },
                                'page_info': {
                                    'pageNo': page_no,
                                    'pageSize': page_size,
                                    'keyWord': next_page_json.get('keyWord', '')
                                },
                                'response_summary': {
                                    'data_count': len(page_data_list)
                                },
                                'is_manual_request': True
                            }

                            # åªåœ¨éœ€è¦å®Œæ•´æ•°æ®æ—¶æ·»åŠ è¯¦ç»†ä¿¡æ¯
                            if self.log_full_data:
                                api_info['headers'] = dict(response.headers)
                                api_info['request_headers'] = headers
                                api_info['request_post_data'] = json.dumps(next_page_json, ensure_ascii=False)
                                api_info['request_json'] = next_page_json
                                api_info['response_body'] = response.text
                                api_info['response_json'] = page_response_json

                            # è®°å½•åˆ°æ•°æ®æ—¥å¿—
                            self.data_logger.info("=" * 80)
                            self.data_logger.info(f"æ‹¦æˆªAPIæ•°æ® #page_{page_no}_manual (ä¸»åŠ¨è¯·æ±‚)")
                            self.data_logger.info("=" * 80)
                            self.data_logger.info(f"APIä¿¡æ¯:\n{json.dumps(api_info, ensure_ascii=False, indent=2)}")
                            self.data_logger.info("=" * 80)

                        except Exception as e:
                            self.logger.error(f"è§£æç¬¬{page_no}é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                    else:
                        self.logger.error(f"ç¬¬{page_no}é¡µè¯·æ±‚å¤±è´¥! çŠ¶æ€ç : {response.status_code}")
                        self.logger.error(f"å“åº”å†…å®¹: {response.text[:200]}")

                except Exception as e:
                    self.logger.error(f"è¯·æ±‚ç¬¬{page_no}é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

            # æ‰€æœ‰é¡µé¢è¯·æ±‚å®Œæˆï¼Œè®°å½•æ±‡æ€»æ•°æ®
            self._log_all_key_data(total, all_data_list)

        except Exception as e:
            self.logger.error(f"è¯·æ±‚æ‰€æœ‰åˆ†é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        finally:
            self._is_requesting_all_pages = False

    def _log_all_key_data(self, total, all_data_list):
        """
        å°†æ‰€æœ‰å…³é”®æ•°æ®æ‰“å°åˆ°æ—¥å¿—
        :param total: æ€»è®°å½•æ•°
        :param all_data_list: æ‰€æœ‰æ•°æ®åˆ—è¡¨
        """
        try:
            self.logger.info("=" * 80)
            self.logger.info("æ‰€æœ‰åˆ†é¡µæ•°æ®æ”¶é›†å®Œæˆ!")
            self.logger.info("=" * 80)
            self.logger.info(f"æ€»è®°å½•æ•°(total): {total}")
            self.logger.info(f"å®é™…æ”¶é›†åˆ°çš„æ•°æ®æ¡æ•°: {len(all_data_list)}")
            self.logger.info("=" * 80)

            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ‰“å°è¯¦ç»†æ•°æ®åˆ°æ§åˆ¶å°
            if not self.log_summary_only:
                self.logger.info("å…³é”®æ•°æ®è¯¦æƒ…:")
                self.logger.info("-" * 80)

                for idx, data_item in enumerate(all_data_list, 1):
                    self.logger.info(f"ç¬¬{idx}æ¡æ•°æ®:")
                    self.logger.info(json.dumps(data_item, ensure_ascii=False, indent=2))
                    self.logger.info("-" * 80)
            else:
                # ä»…æ‘˜è¦æ¨¡å¼ï¼šæ˜¾ç¤ºå‰å‡ æ¡æ•°æ®çš„å…³é”®å­—æ®µ
                self.logger.info("å‰5æ¡æ•°æ®é¢„è§ˆ:")
                for idx, data_item in enumerate(all_data_list[:5], 1):
                    # æå–å…³é”®å­—æ®µï¼ˆæ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼‰
                    key_fields = {k: v for k, v in list(data_item.items())[:3]}  # åªæ˜¾ç¤ºå‰3ä¸ªå­—æ®µ
                    self.logger.info(f"  {idx}. {json.dumps(key_fields, ensure_ascii=False)}")
                if len(all_data_list) > 5:
                    self.logger.info(f"  ... è¿˜æœ‰ {len(all_data_list) - 5} æ¡æ•°æ®")

            # åŒæ—¶è®°å½•åˆ°æ•°æ®æ—¥å¿—ï¼ˆæ€»æ˜¯è®°å½•å®Œæ•´æ•°æ®åˆ°æ•°æ®æ—¥å¿—æ–‡ä»¶ï¼‰
            summary_info = {
                'summary_type': 'all_pages_data',
                'total_records': total,
                'collected_records': len(all_data_list),
                'timestamp': datetime.now().isoformat(),
            }

            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è®°å½•å®Œæ•´æ•°æ®åˆ—è¡¨
            if self.log_full_data:
                summary_info['all_data'] = all_data_list
            else:
                # åªè®°å½•æ•°æ®æ‘˜è¦ç»Ÿè®¡
                summary_info['data_summary'] = {
                    'count': len(all_data_list),
                    'sample': all_data_list[:5] if len(all_data_list) > 0 else []
                }

            self.data_logger.info("=" * 80)
            self.data_logger.info("æ‰€æœ‰åˆ†é¡µæ•°æ®æ±‡æ€»")
            self.data_logger.info("=" * 80)
            self.data_logger.info(json.dumps(summary_info, ensure_ascii=False, indent=2))
            self.data_logger.info("=" * 80)

            self.logger.info("=" * 80)
            self.logger.info("âœ“ æ‰€æœ‰å…³é”®æ•°æ®å·²è®°å½•åˆ°æ—¥å¿—")
            self.logger.info("=" * 80)

        except Exception as e:
            self.logger.error(f"è®°å½•å…³é”®æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

    def scheduled_intercept_and_save(self, xuangu_id="xc0d27d74884930004d1", color="w", action="edit_way",
                                   type="stock", check_interval=1, refresh_interval=15, csv_file_path="scheduled_xuangu_data.csv",
                                   max_refresh_attempts=3):
        """
        å®šæ—¶è¿è¡Œæ¨¡å¼ï¼šè®¿é—®é¡µé¢å¹¶é—´éš”åˆ·æ–°è·å–é€‰è‚¡æ•°æ®ï¼Œä¿å­˜åˆ°æ•°æ®åº“æˆ–CSVæ–‡ä»¶
        ä¸åŸç‰ˆæœ¬ä¸åŒçš„æ˜¯ï¼šè¿™ä¸ªç‰ˆæœ¬æ¯æ¬¡è·å–åˆ°æœ‰æ•ˆæ•°æ®éƒ½ä¼šç«‹å³ä¿å­˜ï¼Œä¸è·³è¿‡ç¬¬ä¸€æ¬¡

        :param xuangu_id: é€‰è‚¡æ–¹æ¡ˆID
        :param color: é¢œè‰²å‚æ•°
        :param action: åŠ¨ä½œå‚æ•°
        :param type: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤ï¼š"stock"ï¼‰
        :param check_interval: æ£€æŸ¥ç½‘ç»œæ—¥å¿—çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        :param refresh_interval: åˆ·æ–°é¡µé¢çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        :param csv_file_path: CSVæ–‡ä»¶ä¿å­˜è·¯å¾„ï¼ˆä»…åœ¨æ•°æ®åº“ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
        :param max_refresh_attempts: æœ€å¤§åˆ·æ–°å°è¯•æ¬¡æ•°ï¼ˆåŒ…å«é¦–æ¬¡è®¿é—®ï¼‰
        """
        try:
            # æ ¹æ®typeè®¾ç½®æ­£ç¡®çš„API URL
            if type in self.api_url_map:
                self.target_api_url = self.api_url_map[type]
                self.logger.info(f"æ ¹æ®type={type}è®¾ç½®API URL: {self.target_api_url}")
            else:
                self.logger.warning(f"æœªçŸ¥çš„type: {type}ï¼Œä½¿ç”¨é»˜è®¤çš„stock API URL")
                self.target_api_url = self.api_url_map["stock"]

            # æ„é€ ç›®æ ‡URL
            url = f"https://xuangu.eastmoney.com/Result?type={type}&color={color}&id={xuangu_id}&a={action}"

            self.logger.info("=" * 80)
            self.logger.info(f"è®¿é—®é¡µé¢: {url}")
            self.logger.info(f"ç›®æ ‡API: {self.target_api_url}")
            if self.use_database:
                self.logger.info("æ•°æ®ä¿å­˜æ–¹å¼: æ•°æ®åº“")
            else:
                self.logger.info(f"æ•°æ®ä¿å­˜æ–¹å¼: CSVæ–‡ä»¶ ({csv_file_path})")
            self.logger.info(f"æœ€å¤§åˆ·æ–°å°è¯•æ¬¡æ•°: {max_refresh_attempts}")
            self.logger.info(f"æ£€æŸ¥é—´éš”: {check_interval}ç§’")
            self.logger.info(f"åˆ·æ–°é—´éš”: {refresh_interval}ç§’")
            self.logger.info("=" * 80)

            # å¯ç”¨ç½‘ç»œæ‹¦æˆª
            self.browser_manager.enable_network_interception()

            # è®¿é—®é¡µé¢
            self.browser_manager.navigate_to(url)

            # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„request_idï¼Œé¿å…é‡å¤å¤„ç†
            processed_request_ids = set()
            # å­˜å‚¨è¯·æ±‚ä¿¡æ¯ï¼Œkeyä¸ºrequest_id
            pending_requests = {}
            intercept_count = 0
            refresh_count = 0
            last_refresh_time = time.time()  # è®¾ç½®åˆå§‹æ—¶é—´ï¼Œç¡®ä¿é¦–æ¬¡åˆ·æ–°è®¡æ—¶æ­£ç¡®

            self.logger.info("=" * 80)
            self.logger.info("å¼€å§‹ç›‘å¬ search-code APIï¼Œç­‰å¾…æœ‰æ•ˆæ•°æ®...")
            self.logger.info("å®šæ—¶è¿è¡Œæ¨¡å¼ï¼šè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®éƒ½ä¼šä¿å­˜")
            self.logger.info("=" * 80)

            # é‡ç½®åˆ†é¡µè·Ÿè¸ªï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½èƒ½è·å–å®Œæ•´æ•°æ®
            self.requested_pages.clear()

            # æŒç»­ç›‘å¬ï¼Œç›´åˆ°è·å–åˆ°æœ‰æ•ˆæ•°æ®æˆ–è¾¾åˆ°æœ€å¤§åˆ·æ–°æ¬¡æ•°
            while refresh_count < max_refresh_attempts:
                try:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°é¡µé¢
                    current_time = time.time()
                    if current_time - last_refresh_time >= refresh_interval:
                        if refresh_count == 0:
                            self.logger.info("é¦–æ¬¡è®¿é—®å®Œæˆï¼Œç­‰å¾…ä¸‹æ¬¡åˆ·æ–°...")
                        else:
                            self.logger.info("=" * 60)
                            self.logger.info(f"ç¬¬ {refresh_count + 1} æ¬¡åˆ·æ–°é¡µé¢...")
                            self.logger.info("=" * 60)

                        self.browser_manager.refresh_page()
                        last_refresh_time = current_time
                        refresh_count += 1

                        # åˆ·æ–°åæ¸…ç©ºå·²å¤„ç†çš„request_idï¼Œä»¥ä¾¿é‡æ–°æ‹¦æˆª
                        processed_request_ids.clear()
                        pending_requests.clear()
                        self.requested_pages.clear()

                    # è·å–æ€§èƒ½æ—¥å¿—
                    logs = self.browser_manager.get_performance_logs()

                    for log in logs:
                        message = json.loads(log['message'])
                        method = message.get('message', {}).get('method', '')

                        # æ‹¦æˆªè¯·æ±‚å‘é€ï¼Œä¿å­˜è¯·æ±‚æ•°æ®
                        if method == 'Network.requestWillBeSent':
                            params = message.get('message', {}).get('params', {})
                            request = params.get('request', {})
                            request_id = params.get('requestId', '')
                            url_sent = request.get('url', '')

                            # åªå¤„ç† search-code API çš„è¯·æ±‚
                            if self.target_api_url in url_sent:
                                pending_requests[request_id] = {
                                    'request_url': url_sent,
                                    'request_method': request.get('method', ''),
                                    'request_headers': request.get('headers', {}),
                                    'request_post_data': request.get('postData', None),
                                    'request_time': datetime.now().isoformat()
                                }

                        # æŸ¥æ‰¾ç½‘ç»œå“åº”
                        if method == 'Network.responseReceived':
                            params = message.get('message', {}).get('params', {})
                            response = params.get('response', {})
                            request_id = params.get('requestId', '')
                            url_received = response.get('url', '')
                            status = response.get('status', 0)
                            mime_type = response.get('mimeType', '')

                            # åªå¤„ç† search-code API
                            if self.target_api_url in url_received and request_id not in processed_request_ids:
                                processed_request_ids.add(request_id)

                                # å°è¯•è·å–å“åº”å†…å®¹
                                try:
                                    body = self.browser_manager.get_response_body(request_id)

                                    # åªå¤„ç†æœ‰æ•°æ®çš„å“åº”ï¼ˆè¿‡æ»¤æµå¼å“åº”ä¸­çš„ç©ºæ•°æ®ï¼‰
                                    if body and len(body) > 10:  # è‡³å°‘è¦æœ‰ä¸€äº›å†…å®¹
                                        intercept_count += 1

                                        self.logger.info("=" * 80)
                                        self.logger.info(f"âœ“ æ‹¦æˆªåˆ°ç¬¬ {intercept_count} ä¸ªæœ‰æ•ˆå“åº”")
                                        self.logger.info(f"URL: {url_received}")
                                        self.logger.info(f"çŠ¶æ€ç : {status}")
                                        self.logger.info(f"å“åº”å¤§å°: {len(body)} å­—ç¬¦")
                                        self.logger.info("=" * 80)

                                        # è§£æå“åº”JSON
                                        response_json = None
                                        try:
                                            response_json = json.loads(body)
                                            if response_json and 'data' in response_json:
                                                data = response_json.get('data', {})
                                                result = data.get('result', {})
                                                data_list = result.get('dataList', [])

                                                self.logger.info(f"âœ“ å“åº”åŒ…å« {len(data_list)} æ¡é€‰è‚¡æ•°æ®")

                                                # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                                                if data_list and len(data_list) > 0:
                                                    # æ ¹æ®é…ç½®é€‰æ‹©ä¿å­˜æ–¹å¼
                                                    if self.use_database:
                                                        self.logger.info("âœ“ è·å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œå¼€å§‹ä¿å­˜åˆ°æ•°æ®åº“")
                                                    else:
                                                        self.logger.info("âœ“ è·å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œå¼€å§‹ä¿å­˜åˆ°CSVæ–‡ä»¶")

                                                    # è·å–è¯·æ±‚ä¿¡æ¯ç”¨äºåˆ†é¡µè¯·æ±‚
                                                    if request_id in pending_requests:
                                                        request_info = pending_requests[request_id]

                                                        # è§£æè¯·æ±‚çš„postData
                                                        request_json = None
                                                        if request_info['request_post_data']:
                                                            try:
                                                                request_json = json.loads(request_info['request_post_data'])
                                                            except Exception as e:
                                                                self.logger.warning(f"è§£æè¯·æ±‚æ•°æ®å¤±è´¥: {e}")

                                                        # å¦‚æœæœ‰è¯·æ±‚æ•°æ®ï¼Œè§¦å‘è‡ªåŠ¨åˆ†é¡µè¯·æ±‚
                                                        if request_json:
                                                            # é‡ç½®åˆ†é¡µè·Ÿè¸ªï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½èƒ½è·å–å®Œæ•´æ•°æ®
                                                            self.requested_pages.clear()
                                                            self.logger.info("å¼€å§‹è‡ªåŠ¨è¯·æ±‚æ‰€æœ‰åˆ†é¡µæ•°æ®...")
                                                            success = self._request_next_page_and_save_to_database(
                                                                request_info, request_json, response_json, type
                                                            )

                                                            if success:
                                                                save_method = "æ•°æ®åº“" if self.use_database else "CSVæ–‡ä»¶"
                                                                self.logger.info("=" * 80)
                                                                self.logger.info(f"âœ“ æ‰€æœ‰åˆ†é¡µæ•°æ®å·²æˆåŠŸä¿å­˜åˆ°{save_method}")
                                                                self.logger.info("=" * 80)
                                                                return True
                                                            else:
                                                                self.logger.error("åˆ†é¡µè¯·æ±‚æˆ–ä¿å­˜å¤±è´¥ï¼Œå°è¯•ä¿å­˜å½“å‰é¡µæ•°æ®")
                                                                # åˆ†é¡µå¤±è´¥ï¼Œå°è¯•ä¿å­˜å½“å‰é¡µæ•°æ®
                                                                if self.use_database:
                                                                    success = self._save_data_to_database(data_list, type)
                                                                else:
                                                                    success = self._save_data_to_csv(data_list, csv_file_path)

                                                                save_method = "æ•°æ®åº“" if self.use_database else "CSVæ–‡ä»¶"
                                                                if success:
                                                                    self.logger.info(f"âœ“ å½“å‰é¡µæ•°æ®å·²ä¿å­˜åˆ°{save_method}")
                                                                    return True
                                                        else:
                                                            # å¦‚æœæ²¡æœ‰è¯·æ±‚æ•°æ®ï¼Œç›´æ¥ä¿å­˜å½“å‰é¡µé¢æ•°æ®
                                                            self.logger.info("æ— è¯·æ±‚æ•°æ®ï¼Œç›´æ¥ä¿å­˜å½“å‰é¡µé¢æ•°æ®")
                                                            if self.use_database:
                                                                success = self._save_data_to_database(data_list, type)
                                                            else:
                                                                success = self._save_data_to_csv(data_list, csv_file_path)

                                                            save_method = "æ•°æ®åº“" if self.use_database else "CSVæ–‡ä»¶"
                                                            if success:
                                                                self.logger.info("=" * 80)
                                                                self.logger.info(f"âœ“ æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°{save_method}")
                                                                self.logger.info("=" * 80)
                                                                return True
                                                            else:
                                                                save_method = "æ•°æ®åº“" if self.use_database else "CSVæ–‡ä»¶"
                                                                self.logger.error(f"ä¿å­˜{save_method}å¤±è´¥")
                                                    else:
                                                        self.logger.warning("æ— æ³•æ‰¾åˆ°è¯·æ±‚ä¿¡æ¯ï¼Œç›´æ¥ä¿å­˜å½“å‰é¡µæ•°æ®")
                                                        if self.use_database:
                                                            success = self._save_data_to_database(data_list, type)
                                                        else:
                                                            success = self._save_data_to_csv(data_list, csv_file_path)

                                                        save_method = "æ•°æ®åº“" if self.use_database else "CSVæ–‡ä»¶"
                                                        if success:
                                                            self.logger.info(f"âœ“ å½“å‰é¡µæ•°æ®å·²ä¿å­˜åˆ°{save_method}")
                                                            return True
                                                else:
                                                    self.logger.warning("å“åº”æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆï¼Œç»§ç»­ç­‰å¾…...")

                                        except Exception as e:
                                            self.logger.warning(f"è§£æå“åº”JSONå¤±è´¥: {e}")

                                        # æ¸…ç†å·²ä½¿ç”¨çš„è¯·æ±‚ä¿¡æ¯
                                        if request_id in pending_requests:
                                            del pending_requests[request_id]

                                except Exception as e:
                                    # è·å–å“åº”ä½“å¤±è´¥ï¼Œå¯èƒ½æ˜¯æµå¼å“åº”è¿˜æ²¡æœ‰æ•°æ®
                                    self.logger.debug(f"è·å–å“åº”ä½“å¤±è´¥: {e}")

                    # å¦‚æœè¿˜æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                    time_until_refresh = max(0, refresh_interval - (time.time() - last_refresh_time))
                    sleep_time = min(check_interval, time_until_refresh)
                    if sleep_time > 0:
                        time.sleep(sleep_time)

                except KeyboardInterrupt:
                    self.logger.info("ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ç¨‹åº")
                    break

            # è¾¾åˆ°æœ€å¤§åˆ·æ–°æ¬¡æ•°ä»æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®
            self.logger.info("=" * 80)
            self.logger.info(f"å·²è¾¾åˆ°æœ€å¤§åˆ·æ–°æ¬¡æ•° {max_refresh_attempts}ï¼Œæœªè·å–åˆ°æœ‰æ•ˆæ•°æ®")
            self.logger.info(f"æ€»å…±æ‹¦æˆªåˆ° {intercept_count} ä¸ªå“åº”")
            self.logger.info("=" * 80)
            return False

        except Exception as e:
            self.logger.error(f"å®šæ—¶æ‹¦æˆªå’Œä¿å­˜å¤±è´¥: {e}", exc_info=True)
            return False

    def _convert_eastmoney_to_db_format(self, data_list, data_type="stock"):
        """
        å°†ä¸œæ–¹è´¢å¯Œæ•°æ®è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
        :param data_list: ä¸œæ–¹è´¢å¯ŒAPIè¿”å›çš„æ•°æ®åˆ—è¡¨
        :param data_type: æ•°æ®ç±»å‹ (stock, etf, fund, bond)
        :return: è½¬æ¢åçš„æ•°æ®åº“æ ¼å¼æ•°æ®åˆ—è¡¨
        """
        try:
            db_data = []
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:00')

            for item in data_list:
                # æ ¹æ®å®é™…çš„ä¸œæ–¹è´¢å¯ŒAPIæ•°æ®ç»“æ„æå–å­—æ®µ
                # ä»CSVæ–‡ä»¶å¤´å¯ä»¥çœ‹å‡ºå®é™…å­—æ®µå
                code = item.get('SECURITY_CODE', '')
                name = item.get('SECURITY_SHORT_NAME', '')

                # ä»NEWEST_PRICEè·å–æœ€æ–°ä»·æ ¼ä½œä¸ºæ”¶ç›˜ä»·
                close_price = self._parse_number(item.get('NEWEST_PRICE', 0))

                # å¦‚æœæ²¡æœ‰æœ€æ–°ä»·æ ¼ï¼Œå°è¯•å…¶ä»–å­—æ®µ
                if close_price == 0:
                    close_price = self._parse_number(item.get('CLOSE', item.get('f2', 0)))

                # å¼€ç›˜ä»·ï¼Œå¦‚æœæ²¡æœ‰ç°æˆå­—æ®µï¼Œç”¨æ”¶ç›˜ä»·ä»£æ›¿
                # ä¸œæ–¹è´¢å¯Œé€‰è‚¡APIé€šå¸¸ä¸æä¾›å¼€ç›˜ä»·
                open_price = close_price

                # æœ€é«˜ä»·å’Œæœ€ä½ä»·
                high_price = self._parse_number(item.get('PEAK_PRICE<140>', item.get('PEAK_PRICE', close_price)))
                low_price = self._parse_number(item.get('BOTTOM_PRICE<140>', item.get('BOTTOM_PRICE', close_price)))

                # æˆäº¤é‡å¤„ç†
                volume_str = item.get('VOLUME', '0')
                volume = self._parse_number(volume_str)

                # æˆäº¤é¢å¤„ç†
                amount_str = item.get('TRADING_VOLUMES', '0')
                amount = self._parse_number(amount_str)

                db_record = {
                    'code': code,
                    'name': name,
                    'datetime': current_time,
                    'open': open_price,
                    'high': high_price,
                    'low': low_price,
                    'close': close_price,
                    'volume': int(volume),
                    'amount': amount
                }

                # åªæœ‰å½“ä»£ç å’Œåç§°éƒ½ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
                if code and name:
                    db_data.append(db_record)
                    self.logger.debug(f"è½¬æ¢æ•°æ®: {name}({code}) - ä»·æ ¼:{close_price}, æˆäº¤é‡:{volume}")

            self.logger.info(f"âœ“ æˆåŠŸè½¬æ¢ {len(db_data)} æ¡æ•°æ®åˆ°æ•°æ®åº“æ ¼å¼")
            return db_data

        except Exception as e:
            self.logger.error(f"æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥: {e}", exc_info=True)
            return []

    def _parse_number(self, value_str):
        """
        è§£ææ•°å­—å­—ç¬¦ä¸²ï¼Œå¤„ç†ä¸­æ–‡å•ä½ï¼ˆäº¿ã€ä¸‡ç­‰ï¼‰
        :param value_str: æ•°å­—å­—ç¬¦ä¸²ï¼Œå¯èƒ½åŒ…å«ä¸­æ–‡å•ä½
        :return: æµ®ç‚¹æ•°
        """
        try:
            if not value_str or value_str == '0' or value_str == '-':
                return 0.0

            value_str = str(value_str).strip()

            # å¤„ç†ä¸­æ–‡å•ä½
            if 'äº¿' in value_str:
                number_part = value_str.replace('äº¿', '').strip()
                return float(number_part) * 100000000
            elif 'ä¸‡' in value_str:
                number_part = value_str.replace('ä¸‡', '').strip()
                return float(number_part) * 10000
            elif 'åƒ' in value_str:
                number_part = value_str.replace('åƒ', '').strip()
                return float(number_part) * 1000
            else:
                # çº¯æ•°å­—
                return float(value_str)

        except (ValueError, TypeError) as e:
            self.logger.debug(f"è§£ææ•°å­—å¤±è´¥: {value_str} - {e}")
            return 0.0

    def _save_data_to_csv(self, data_list, csv_file_path):
        """
        å°†é€‰è‚¡æ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼‰
        :param data_list: é€‰è‚¡æ•°æ®åˆ—è¡¨
        :param csv_file_path: CSVæ–‡ä»¶ä¿å­˜è·¯å¾„
        :return: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            if not data_list:
                self.logger.warning("æ•°æ®åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜åˆ°CSVæ–‡ä»¶")
                return False

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
            file_exists = os.path.exists(csv_file_path)

            with open(csv_file_path, 'a', newline='', encoding='utf-8-sig') as csvfile:
                if data_list:
                    # è·å–ç¬¬ä¸€æ¡æ•°æ®ä½œä¸ºè¡¨å¤´
                    fieldnames = list(data_list[0].keys())
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
                    if not file_exists:
                        writer.writeheader()
                        self.logger.info(f"åˆ›å»ºæ–°çš„CSVæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´: {csv_file_path}")

                    # å†™å…¥æ•°æ®
                    writer.writerows(data_list)

                    self.logger.info(f"âœ“ æˆåŠŸå†™å…¥ {len(data_list)} æ¡æ•°æ®åˆ°CSVæ–‡ä»¶")
                    self.logger.info(f"æ–‡ä»¶è·¯å¾„: {csv_file_path}")
                    return True
                else:
                    self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä»¥å†™å…¥CSVæ–‡ä»¶")
                    return False

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            return False

    def _save_data_to_database(self, data_list, data_type="stock"):
        """
        å°†é€‰è‚¡æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
        :param data_list: é€‰è‚¡æ•°æ®åˆ—è¡¨
        :param data_type: æ•°æ®ç±»å‹ (stock, etf, fund, bond)
        :return: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            if not self.use_database or not self.db:
                self.logger.warning("æ•°æ®åº“æœªå¯ç”¨ï¼Œæ— æ³•ä¿å­˜åˆ°æ•°æ®åº“")
                return False

            if not data_list:
                self.logger.warning("æ•°æ®åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜åˆ°æ•°æ®åº“")
                return False

            # è½¬æ¢æ•°æ®æ ¼å¼
            db_data = self._convert_eastmoney_to_db_format(data_list, data_type)

            if not db_data:
                self.logger.warning("è½¬æ¢åçš„æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜åˆ°æ•°æ®åº“")
                return False

            # ä½¿ç”¨åˆ†é’Ÿæ•°æ®å‘¨æœŸä¿å­˜
            period = "1m"  # é€‰è‚¡æ•°æ®é€šå¸¸æ˜¯æ—¥çº¿æ•°æ®

            # ä¿å­˜åˆ°æ•°æ®åº“
            inserted_count = self.db.insert_kline_data(period, db_data)

            if inserted_count > 0:
                self.logger.info(f"âœ“ æˆåŠŸä¿å­˜ {inserted_count} æ¡æ•°æ®åˆ°æ•°æ®åº“")
                self.logger.info(f"æ•°æ®ç±»å‹: {data_type}, å‘¨æœŸ: {period}")
                return True
            else:
                self.logger.warning("æ•°æ®åº“æ’å…¥è¿”å›0æ¡è®°å½•")
                return False

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}", exc_info=True)
            return False

    def _request_next_page_and_save_to_database(self, request_info, request_json, first_page_response=None, type="stock"):
        """
        æ ¹æ®ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼Œè‡ªåŠ¨è¯·æ±‚æ‰€æœ‰åˆ†é¡µå¹¶ä¿å­˜åˆ°æ•°æ®åº“
        :param request_info: åŸå§‹è¯·æ±‚ä¿¡æ¯
        :param request_json: åŸå§‹è¯·æ±‚çš„JSONæ•°æ®
        :param first_page_response: ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
        :param type: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤ï¼š"stock"ï¼‰
        :return: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # é¿å…é‡å¤è¯·æ±‚
            if hasattr(self, '_is_requesting_all_pages_db') and self._is_requesting_all_pages_db:
                return False

            self._is_requesting_all_pages_db = True

            # é‡ç½®åˆ†é¡µè·Ÿè¸ªï¼Œç¡®ä¿æ¯æ¬¡éƒ½èƒ½è·å–å®Œæ•´æ•°æ®
            self.requested_pages.clear()

            # è§£æç¬¬ä¸€é¡µæ•°æ®ï¼Œè·å–totalå’ŒdataList
            if not first_page_response:
                self.logger.warning("æœªæä¾›ç¬¬ä¸€é¡µå“åº”æ•°æ®ï¼Œæ— æ³•è¯·æ±‚åç»­åˆ†é¡µ")
                return False

            # æå–totalå’ŒdataList
            try:
                data = first_page_response.get('data', {})
                result = data.get('result', {})
                total = result.get('total', 0)
                first_page_data_list = result.get('dataList', [])

                self.logger.info("=" * 80)
                self.logger.info(f"ç¬¬ä¸€é¡µæ•°æ®è§£æ:")
                self.logger.info(f"  æ€»è®°å½•æ•°(total): {total}")
                self.logger.info(f"  ç¬¬ä¸€é¡µæ•°æ®æ¡æ•°: {len(first_page_data_list)}")
                self.logger.info("=" * 80)

                if total == 0:
                    self.logger.warning("æ€»è®°å½•æ•°ä¸º0ï¼Œæ— éœ€è¯·æ±‚åç»­åˆ†é¡µ")
                    return False

                # æ”¶é›†æ‰€æœ‰æ•°æ®
                all_data_list = first_page_data_list.copy()

            except Exception as e:
                self.logger.error(f"è§£æç¬¬ä¸€é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                return False

            # è®¡ç®—æ€»é¡µæ•°
            page_size = request_json.get('pageSize', 50)
            total_pages = (total + page_size - 1) // page_size  # å‘ä¸Šå–æ•´

            self.logger.info(f"æ¯é¡µå¤§å°: {page_size}")
            self.logger.info(f"è®¡ç®—æ€»é¡µæ•°: {total_pages}")
            self.logger.info("=" * 80)

            # å¦‚æœåªæœ‰ä¸€é¡µï¼Œç›´æ¥ä¿å­˜ç¬¬ä¸€é¡µæ•°æ®
            if total_pages <= 1:
                self.logger.info("åªæœ‰1é¡µæ•°æ®ï¼Œç›´æ¥ä¿å­˜ç¬¬ä¸€é¡µæ•°æ®")
                success = self._save_data_to_database(all_data_list, type)
                return success

            # è¯·æ±‚åç»­é¡µé¢ (ä»ç¬¬2é¡µå¼€å§‹)
            url = request_info['request_url']
            headers = request_info['request_headers'].copy()
            headers['Content-Type'] = 'application/json'

            for page_no in range(2, total_pages + 1):
                # æ£€æŸ¥æ˜¯å¦å·²è¯·æ±‚è¿‡
                if page_no in self.requested_pages:
                    continue

                self.requested_pages.add(page_no)

                # å»¶æ—¶1ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                self.logger.info(f"å»¶æ—¶1ç§’åè¯·æ±‚ç¬¬{page_no}é¡µ...")
                time.sleep(1)

                # å¤åˆ¶è¯·æ±‚æ•°æ®
                next_page_json = request_json.copy()

                # ä¿®æ”¹é¡µç 
                if 'pageNo' in next_page_json:
                    next_page_json['pageNo'] = page_no
                elif 'pageNum' in next_page_json:
                    next_page_json['pageNum'] = page_no
                elif 'page' in next_page_json:
                    next_page_json['page'] = page_no

                # éšæœºåŒ–requestIdï¼Œé¿å…åçˆ¬
                if 'requestId' in next_page_json:
                    next_page_json['requestId'] = self._randomize_request_id(next_page_json['requestId'])

                # å‘èµ·è¯·æ±‚
                self.logger.info(f"æ­£åœ¨è¯·æ±‚ç¬¬{page_no}/{total_pages}é¡µ...")
                self.logger.info(f"è¯·æ±‚URL: {url}")

                try:
                    response = requests.post(
                        url,
                        json=next_page_json,
                        headers=headers,
                        timeout=30
                    )

                    if response.status_code == 200:
                        self.logger.info(f"âœ“ ç¬¬{page_no}é¡µè¯·æ±‚æˆåŠŸ! çŠ¶æ€ç : {response.status_code}")
                        self.logger.info(f"âœ“ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")

                        # è§£æå“åº”æ•°æ®
                        try:
                            page_response_json = response.json()
                            page_data = page_response_json.get('data', {})
                            page_result = page_data.get('result', {})
                            page_data_list = page_result.get('dataList', [])

                            self.logger.info(f"âœ“ ç¬¬{page_no}é¡µæ•°æ®æ¡æ•°: {len(page_data_list)}")

                            # æ”¶é›†æ•°æ®
                            all_data_list.extend(page_data_list)

                        except Exception as e:
                            self.logger.error(f"è§£æç¬¬{page_no}é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                    else:
                        self.logger.error(f"ç¬¬{page_no}é¡µè¯·æ±‚å¤±è´¥! çŠ¶æ€ç : {response.status_code}")
                        self.logger.error(f"å“åº”å†…å®¹: {response.text[:200]}")

                except Exception as e:
                    self.logger.error(f"è¯·æ±‚ç¬¬{page_no}é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

            # æ‰€æœ‰é¡µé¢è¯·æ±‚å®Œæˆï¼Œä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            self.logger.info("=" * 80)
            self.logger.info("æ‰€æœ‰åˆ†é¡µæ•°æ®æ”¶é›†å®Œæˆ!")
            self.logger.info(f"æ€»è®°å½•æ•°(total): {total}")
            self.logger.info(f"å®é™…æ”¶é›†åˆ°çš„æ•°æ®æ¡æ•°: {len(all_data_list)}")
            self.logger.info("=" * 80)

            success = self._save_data_to_database(all_data_list, type)
            if success:
                self.logger.info("âœ“ æ‰€æœ‰åˆ†é¡µæ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
            return success

        except Exception as e:
            self.logger.error(f"è¯·æ±‚æ‰€æœ‰åˆ†é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False
        finally:
            self._is_requesting_all_pages_db = False

    def _request_next_page_and_save_to_csv(self, request_info, request_json, first_page_response=None, type="stock", csv_file_path="xuangu_data.csv"):
        """
        æ ¹æ®ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼Œè‡ªåŠ¨è¯·æ±‚æ‰€æœ‰åˆ†é¡µå¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶
        :param request_info: åŸå§‹è¯·æ±‚ä¿¡æ¯
        :param request_json: åŸå§‹è¯·æ±‚çš„JSONæ•°æ®
        :param first_page_response: ç¬¬ä¸€é¡µçš„å“åº”æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
        :param type: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤ï¼š"stock"ï¼‰
        :param csv_file_path: CSVæ–‡ä»¶ä¿å­˜è·¯å¾„
        :return: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # é¿å…é‡å¤è¯·æ±‚
            if hasattr(self, '_is_requesting_all_pages_csv') and self._is_requesting_all_pages_csv:
                return False

            self._is_requesting_all_pages_csv = True

            # é‡ç½®åˆ†é¡µè·Ÿè¸ªï¼Œç¡®ä¿æ¯æ¬¡éƒ½èƒ½è·å–å®Œæ•´æ•°æ®
            self.requested_pages.clear()

            # è§£æç¬¬ä¸€é¡µæ•°æ®ï¼Œè·å–totalå’ŒdataList
            if not first_page_response:
                self.logger.warning("æœªæä¾›ç¬¬ä¸€é¡µå“åº”æ•°æ®ï¼Œæ— æ³•è¯·æ±‚åç»­åˆ†é¡µ")
                return False

            # æå–totalå’ŒdataList
            try:
                data = first_page_response.get('data', {})
                result = data.get('result', {})
                total = result.get('total', 0)
                first_page_data_list = result.get('dataList', [])

                self.logger.info("=" * 80)
                self.logger.info(f"ç¬¬ä¸€é¡µæ•°æ®è§£æ:")
                self.logger.info(f"  æ€»è®°å½•æ•°(total): {total}")
                self.logger.info(f"  ç¬¬ä¸€é¡µæ•°æ®æ¡æ•°: {len(first_page_data_list)}")
                self.logger.info("=" * 80)

                if total == 0:
                    self.logger.warning("æ€»è®°å½•æ•°ä¸º0ï¼Œæ— éœ€è¯·æ±‚åç»­åˆ†é¡µ")
                    return False

                # æ”¶é›†æ‰€æœ‰æ•°æ®
                all_data_list = first_page_data_list.copy()

            except Exception as e:
                self.logger.error(f"è§£æç¬¬ä¸€é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                return False

            # è®¡ç®—æ€»é¡µæ•°
            page_size = request_json.get('pageSize', 50)
            total_pages = (total + page_size - 1) // page_size  # å‘ä¸Šå–æ•´

            self.logger.info(f"æ¯é¡µå¤§å°: {page_size}")
            self.logger.info(f"è®¡ç®—æ€»é¡µæ•°: {total_pages}")
            self.logger.info("=" * 80)

            # å¦‚æœåªæœ‰ä¸€é¡µï¼Œç›´æ¥ä¿å­˜ç¬¬ä¸€é¡µæ•°æ®
            if total_pages <= 1:
                self.logger.info("åªæœ‰1é¡µæ•°æ®ï¼Œç›´æ¥ä¿å­˜ç¬¬ä¸€é¡µæ•°æ®")
                success = self._save_data_to_csv(all_data_list, csv_file_path)
                return success

            # è¯·æ±‚åç»­é¡µé¢ (ä»ç¬¬2é¡µå¼€å§‹)
            url = request_info['request_url']
            headers = request_info['request_headers'].copy()
            headers['Content-Type'] = 'application/json'

            for page_no in range(2, total_pages + 1):
                # æ£€æŸ¥æ˜¯å¦å·²è¯·æ±‚è¿‡
                if page_no in self.requested_pages:
                    continue

                self.requested_pages.add(page_no)

                # å»¶æ—¶1ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                self.logger.info(f"å»¶æ—¶1ç§’åè¯·æ±‚ç¬¬{page_no}é¡µ...")
                time.sleep(1)

                # å¤åˆ¶è¯·æ±‚æ•°æ®
                next_page_json = request_json.copy()

                # ä¿®æ”¹é¡µç 
                if 'pageNo' in next_page_json:
                    next_page_json['pageNo'] = page_no
                elif 'pageNum' in next_page_json:
                    next_page_json['pageNum'] = page_no
                elif 'page' in next_page_json:
                    next_page_json['page'] = page_no

                # éšæœºåŒ–requestIdï¼Œé¿å…åçˆ¬
                if 'requestId' in next_page_json:
                    next_page_json['requestId'] = self._randomize_request_id(next_page_json['requestId'])

                # å‘èµ·è¯·æ±‚
                self.logger.info(f"æ­£åœ¨è¯·æ±‚ç¬¬{page_no}/{total_pages}é¡µ...")
                self.logger.info(f"è¯·æ±‚URL: {url}")

                try:
                    response = requests.post(
                        url,
                        json=next_page_json,
                        headers=headers,
                        timeout=30
                    )

                    if response.status_code == 200:
                        self.logger.info(f"âœ“ ç¬¬{page_no}é¡µè¯·æ±‚æˆåŠŸ! çŠ¶æ€ç : {response.status_code}")
                        self.logger.info(f"âœ“ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")

                        # è§£æå“åº”æ•°æ®
                        try:
                            page_response_json = response.json()
                            page_data = page_response_json.get('data', {})
                            page_result = page_data.get('result', {})
                            page_data_list = page_result.get('dataList', [])

                            self.logger.info(f"âœ“ ç¬¬{page_no}é¡µæ•°æ®æ¡æ•°: {len(page_data_list)}")

                            # æ”¶é›†æ•°æ®
                            all_data_list.extend(page_data_list)

                        except Exception as e:
                            self.logger.error(f"è§£æç¬¬{page_no}é¡µå“åº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
                    else:
                        self.logger.error(f"ç¬¬{page_no}é¡µè¯·æ±‚å¤±è´¥! çŠ¶æ€ç : {response.status_code}")
                        self.logger.error(f"å“åº”å†…å®¹: {response.text[:200]}")

                except Exception as e:
                    self.logger.error(f"è¯·æ±‚ç¬¬{page_no}é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

            # æ‰€æœ‰é¡µé¢è¯·æ±‚å®Œæˆï¼Œä¿å­˜æ•°æ®åˆ°CSV
            self.logger.info("=" * 80)
            self.logger.info("æ‰€æœ‰åˆ†é¡µæ•°æ®æ”¶é›†å®Œæˆ!")
            self.logger.info(f"æ€»è®°å½•æ•°(total): {total}")
            self.logger.info(f"å®é™…æ”¶é›†åˆ°çš„æ•°æ®æ¡æ•°: {len(all_data_list)}")
            self.logger.info("=" * 80)

            success = self._save_data_to_csv(all_data_list, csv_file_path)
            if success:
                self.logger.info("âœ“ æ‰€æœ‰åˆ†é¡µæ•°æ®å·²æˆåŠŸä¿å­˜åˆ°CSVæ–‡ä»¶")
            return success

        except Exception as e:
            self.logger.error(f"è¯·æ±‚æ‰€æœ‰åˆ†é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False
        finally:
            self._is_requesting_all_pages_csv = False

    def add_api_type(self, type_name, api_url):
        """
        åŠ¨æ€æ·»åŠ æ–°çš„APIç±»å‹
        :param type_name: ç±»å‹åç§°
        :param api_url: å¯¹åº”çš„API URL
        """
        self.api_url_map[type_name] = api_url
        self.logger.info(f"æ·»åŠ æ–°çš„APIç±»å‹: {type_name} -> {api_url}")

    def get_available_types(self):
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„APIç±»å‹
        :return: å¯ç”¨ç±»å‹åˆ—è¡¨
        """
        return list(self.api_url_map.keys())

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        self.browser_manager.close()


def main():
    """
    ä¸»å‡½æ•° - å¯åŠ¨å®šæ—¶è¿è¡Œçš„ search-code API æ‹¦æˆªå™¨
    æ¯5åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°é¡µé¢å¹¶ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
    """
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    FinancialLogger.setup_logging(
        log_dir="logs",
        log_level=20,  # INFOçº§åˆ«
        console_output=True
    )

    logger = get_logger('financial_framework.eastmoney_interceptor_main')
    logger.info("=" * 80)
    logger.info("ä¸œæ–¹è´¢å¯Œé€‰è‚¡ search-code API å®šæ—¶æ‹¦æˆªå™¨")
    logger.info("æ¨¡å¼ï¼šæ¯5åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°å¹¶ä¿å­˜æ•°æ®")
    logger.info("=" * 80)

    # åˆå§‹åŒ–æ‹¦æˆªå™¨
    logger.info("=" * 80)
    # æ—¥å¿—é…ç½®å‚æ•°è¯´æ˜ï¼š
    # - log_full_data=False: ä¸è®°å½•å®Œæ•´çš„è¯·æ±‚å’Œå“åº”æ•°æ®åˆ°æ•°æ®æ—¥å¿—ï¼ˆèŠ‚çœç©ºé—´ï¼‰
    # - log_summary_only=True: æ§åˆ¶å°åªæ˜¾ç¤ºå…³é”®æ‘˜è¦ä¿¡æ¯ï¼ˆç®€æ´æ¨¡å¼ï¼‰
    # - use_database=True: ä½¿ç”¨æ•°æ®åº“ä¿å­˜æ•°æ®ï¼ˆè®¾ä¸ºFalseåˆ™ä½¿ç”¨CSVæ–‡ä»¶ï¼‰
    interceptor = EastmoneySearchCodeInterceptor(
        headless=False,
        log_full_data=False,      # è®¾ä¸º True åˆ™è®°å½•å®Œæ•´æ•°æ®
        log_summary_only=True,    # è®¾ä¸º False åˆ™æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        use_database=True         # è®¾ä¸º False åˆ™ä½¿ç”¨CSVæ–‡ä»¶ä¿å­˜
    )

    if not interceptor.browser_manager.is_initialized():
        logger.error("æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        return

    # æ˜¾ç¤ºå¯ç”¨çš„APIç±»å‹
    available_types = interceptor.get_available_types()
    logger.info(f"å¯ç”¨çš„APIç±»å‹: {', '.join(available_types)}")

    # å®šæ—¶è¿è¡Œå‚æ•°
    SCHEDULE_INTERVAL = 120  # 5åˆ†é’Ÿ = 300ç§’
    CSV_BASE_PATH = "data/scheduled_xuangu_data.csv"

    # é…ç½®å‚æ•°
    config = {
        "xuangu_id": "xc0d3858a90493012efd",
        "color": "w",
        "action": "edit_way",
        "type": "stock",               # æ•°æ®ç±»å‹
        "check_interval": 1,           # æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡ç½‘ç»œæ—¥å¿—
        "refresh_interval": 15,        # æ¯15ç§’åˆ·æ–°ä¸€æ¬¡é¡µé¢ï¼ˆç”¨äºå•æ¬¡æ•°æ®è·å–ï¼‰
        "max_refresh_attempts": 3      # æœ€å¤§åˆ·æ–°å°è¯•æ¬¡æ•°ï¼ˆç”¨äºå•æ¬¡æ•°æ®è·å–ï¼‰
    }

    run_count = 0
    logger.info("=" * 80)
    logger.info(f"å®šæ—¶è¿è¡Œé…ç½®:")
    logger.info(f"è¿è¡Œé—´éš”: {SCHEDULE_INTERVAL}ç§’ ({SCHEDULE_INTERVAL/60:.1f}åˆ†é’Ÿ)")
    logger.info(f"æ•°æ®ä¿å­˜è·¯å¾„: {CSV_BASE_PATH}")
    logger.info(f"é€‰è‚¡æ–¹æ¡ˆID: {config['xuangu_id']}")
    logger.info(f"æ•°æ®ç±»å‹: {config['type']}")
    logger.info("=" * 80)
    logger.info("å¼€å§‹å®šæ—¶è¿è¡Œï¼ŒæŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    logger.info("=" * 80)

    try:
        while True:
            run_count += 1
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            logger.info("=" * 80)
            logger.info(f"ç¬¬ {run_count} æ¬¡è¿è¡Œ - {current_time}")
            logger.info("=" * 80)

            # ä¸ºæ¯æ¬¡è¿è¡Œç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„CSVæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_file_path = f"data/scheduled_xuangu_data_{timestamp}.csv"

            logger.info(f"æœ¬æ¬¡è¿è¡Œæ•°æ®å°†ä¿å­˜åˆ°: {csv_file_path}")
            logger.info("å¼€å§‹è·å–é€‰è‚¡æ•°æ®...")

            # æ‰§è¡Œå•æ¬¡æ•°æ®è·å–ï¼ˆä½¿ç”¨å®šæ—¶è¿è¡Œä¸“ç”¨çš„æ–¹æ³•ï¼‰
            success = interceptor.scheduled_intercept_and_save(
                csv_file_path=csv_file_path,
                **config
            )

            if success:
                logger.info("=" * 80)
                logger.info(f"âœ“ ç¬¬ {run_count} æ¬¡è¿è¡Œå®Œæˆï¼Œæ•°æ®å·²ä¿å­˜")
                logger.info(f"âœ“ æ•°æ®æ–‡ä»¶: {csv_file_path}")
                logger.info("=" * 80)
            else:
                logger.warning("=" * 80)
                logger.warning(f"âœ— ç¬¬ {run_count} æ¬¡è¿è¡Œå¤±è´¥æˆ–æœªè·å–åˆ°æ•°æ®")
                logger.warning("=" * 80)

            # è®¡ç®—ä¸‹æ¬¡è¿è¡Œæ—¶é—´
            next_run_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logger.info(f"ä¸‹æ¬¡è¿è¡Œæ—¶é—´: {next_run_time} (ç­‰å¾… {SCHEDULE_INTERVAL} ç§’)")
            logger.info("=" * 80)

            # ç­‰å¾…æŒ‡å®šæ—¶é—´é—´éš”
            try:
                time.sleep(SCHEDULE_INTERVAL)
            except KeyboardInterrupt:
                logger.info("ç”¨æˆ·åœ¨ç­‰å¾…æœŸé—´åœæ­¢ç¨‹åº")
                break

    except KeyboardInterrupt:
        logger.info("=" * 80)
        logger.info("ç”¨æˆ·æ‰‹åŠ¨åœæ­¢å®šæ—¶è¿è¡Œç¨‹åº")
        logger.info(f"æ€»å…±è¿è¡Œäº† {run_count} æ¬¡")
        logger.info("=" * 80)
    except Exception as e:
        logger.error(f"å®šæ—¶è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
    finally:
        interceptor.close()

    logger.info("=" * 80)
    logger.info("å®šæ—¶ç¨‹åºç»“æŸ")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()